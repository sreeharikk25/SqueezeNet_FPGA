# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hOUbD5MBrSoZrMTT7roxpT6PZb4sgBmY
"""

# -*- coding: utf-8 -*-
"""
EE 511 - Test SqueezeNet with HLS-compatible quantization
FIXED VERSION - Properly matches HLS fire_module.cpp and other layers
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import numpy as np
import os

DEVICE = "cpu"

# =============================================================================
# Quantization - Matches HLS ap_fixed<8,4>
# =============================================================================
SCALE = 16
QMIN = -128
QMAX = 127
REAL_MIN = -8.0
REAL_MAX = 7.9375

def quantize_tensor(x):
    """Simulates casting to ap_fixed<8,4> in HLS"""
    x_clamped = torch.clamp(x, REAL_MIN, REAL_MAX)
    x_int = torch.round(x_clamped * SCALE)
    x_int = torch.clamp(x_int, QMIN, QMAX)
    return x_int / SCALE


# =============================================================================
# Fire Module - HLS Simulation (FIXED)
# Matches fire_module.cpp behavior exactly
# =============================================================================

class FireHLS(nn.Module):
    def __init__(self, in_ch, sq_ch, e1_ch, e3_ch):
        super().__init__()
        self.squeeze = nn.Conv2d(in_ch, sq_ch, 1, bias=True)
        self.expand1x1 = nn.Conv2d(sq_ch, e1_ch, 1, bias=True)
        self.expand3x3 = nn.Conv2d(sq_ch, e3_ch, 3, padding=1, bias=True)

    def forward(self, x):
        # Input x is already quantized from previous layer

        # Step 1: Squeeze layer (1x1 conv + ReLU)
        # In HLS: squeeze_layer does conv, ReLU, then output is data_t
        x = F.conv2d(x, self.squeeze.weight, self.squeeze.bias)
        x = F.relu(x)
        x = quantize_tensor(x)  # Matches: data_t out_val = (data_t)sum; + ReLU

        # Step 2: Expand 1x1 (no ReLU yet)
        # In HLS: expand1x1_layer writes (data_t)sum to output
        o1 = F.conv2d(x, self.expand1x1.weight, self.expand1x1.bias)
        o1 = quantize_tensor(o1)  # FIXED: Matches output[out_idx] = (data_t)sum

        # Step 3: Expand 3x3 (no ReLU yet)
        # In HLS: expand3x3_layer writes (data_t)sum to output
        o3 = F.conv2d(x, self.expand3x3.weight, self.expand3x3.bias, padding=1)
        o3 = quantize_tensor(o3)  # FIXED: Matches output[out_idx] = (data_t)sum

        # Step 4: Concatenate and apply ReLU
        # In HLS: apply_relu_inplace on concatenated output
        out = torch.cat([o1, o3], dim=1)
        out = F.relu(out)
        # Note: After ReLU on already-quantized values, result is still quantized
        # (ReLU only zeros negatives, doesn't change positive quantized values)

        return out


# =============================================================================
# SqueezeNet - HLS Simulation (FIXED)
# =============================================================================

class SqueezeNetHLS(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()

        self.conv1 = nn.Conv2d(3, 96, 7, stride=2, padding=3, bias=True)

        self.fire2 = FireHLS(96, 16, 64, 64)
        self.fire3 = FireHLS(128, 16, 64, 64)
        self.fire4 = FireHLS(128, 32, 128, 128)
        self.fire5 = FireHLS(256, 32, 128, 128)
        self.fire6 = FireHLS(256, 48, 192, 192)
        self.fire7 = FireHLS(384, 48, 192, 192)
        self.fire8 = FireHLS(384, 64, 256, 256)
        self.fire9 = FireHLS(512, 64, 256, 256)

        self.pool = nn.MaxPool2d(3, stride=2, ceil_mode=True)
        self.conv10 = nn.Conv2d(512, num_classes, 1, bias=True)
        self.avg = nn.AdaptiveAvgPool2d(1)

    def forward(self, x):
        # Quantize input image (simulates fixed-point input preprocessing)
        x = quantize_tensor(x)

        # Conv1 + ReLU
        # In HLS conv7x7: output[out_idx] = (data_t)sum after optional ReLU
        x = F.conv2d(x, self.conv1.weight, self.conv1.bias, stride=2, padding=3)
        x = F.relu(x)
        x = quantize_tensor(x)

        # MaxPool1
        # MaxPool doesn't change quantized values, just selects max
        x = self.pool(x)

        # Fire modules (each handles quantization internally)
        x = self.fire2(x)
        x = self.fire3(x)
        x = self.fire4(x)
        x = self.pool(x)

        x = self.fire5(x)
        x = self.fire6(x)
        x = self.fire7(x)
        x = self.fire8(x)
        x = self.pool(x)

        x = self.fire9(x)

        # Conv10 (classifier) + ReLU
        # In HLS conv1x1: output = (data_t)sum
        x = F.conv2d(x, self.conv10.weight, self.conv10.bias)
        x = F.relu(x)
        x = quantize_tensor(x)

        # Global Average Pooling
        # In HLS global_avgpool: output[c] = (data_t)(sum * inv_hw)
        x = self.avg(x)
        x = quantize_tensor(x)  # FIXED: Matches HLS GAP output quantization

        return torch.flatten(x, 1)


# =============================================================================
# Load Weights from .bin Files
# =============================================================================

def load_weights_from_bin(model, weights_bin_path, biases_bin_path):
    """Load quantized weights from .bin files."""

    # Load binary data
    weights_int8 = np.fromfile(weights_bin_path, dtype=np.int8)
    biases_int8 = np.fromfile(biases_bin_path, dtype=np.int8)

    # Convert to float Q3.4 representation
    weights = weights_int8.astype(np.float32) / SCALE
    biases = biases_int8.astype(np.float32) / SCALE

    print(f"Loaded {len(weights):,} weights and {len(biases):,} biases")

    # Layer definitions: (name, conv_layer, out_ch, in_ch, kernel_size)
    layers = [
        ('conv1', model.conv1, 96, 3, 7),
        ('fire2_squeeze', model.fire2.squeeze, 16, 96, 1),
        ('fire2_expand1x1', model.fire2.expand1x1, 64, 16, 1),
        ('fire2_expand3x3', model.fire2.expand3x3, 64, 16, 3),
        ('fire3_squeeze', model.fire3.squeeze, 16, 128, 1),
        ('fire3_expand1x1', model.fire3.expand1x1, 64, 16, 1),
        ('fire3_expand3x3', model.fire3.expand3x3, 64, 16, 3),
        ('fire4_squeeze', model.fire4.squeeze, 32, 128, 1),
        ('fire4_expand1x1', model.fire4.expand1x1, 128, 32, 1),
        ('fire4_expand3x3', model.fire4.expand3x3, 128, 32, 3),
        ('fire5_squeeze', model.fire5.squeeze, 32, 256, 1),
        ('fire5_expand1x1', model.fire5.expand1x1, 128, 32, 1),
        ('fire5_expand3x3', model.fire5.expand3x3, 128, 32, 3),
        ('fire6_squeeze', model.fire6.squeeze, 48, 256, 1),
        ('fire6_expand1x1', model.fire6.expand1x1, 192, 48, 1),
        ('fire6_expand3x3', model.fire6.expand3x3, 192, 48, 3),
        ('fire7_squeeze', model.fire7.squeeze, 48, 384, 1),
        ('fire7_expand1x1', model.fire7.expand1x1, 192, 48, 1),
        ('fire7_expand3x3', model.fire7.expand3x3, 192, 48, 3),
        ('fire8_squeeze', model.fire8.squeeze, 64, 384, 1),
        ('fire8_expand1x1', model.fire8.expand1x1, 256, 64, 1),
        ('fire8_expand3x3', model.fire8.expand3x3, 256, 64, 3),
        ('fire9_squeeze', model.fire9.squeeze, 64, 512, 1),
        ('fire9_expand1x1', model.fire9.expand1x1, 256, 64, 1),
        ('fire9_expand3x3', model.fire9.expand3x3, 256, 64, 3),
        ('conv10', model.conv10, 10, 512, 1),
    ]

    w_offset = 0
    b_offset = 0

    for name, layer, out_ch, in_ch, k in layers:
        num_w = out_ch * in_ch * k * k
        num_b = out_ch

        w = weights[w_offset:w_offset + num_w].reshape(out_ch, in_ch, k, k)
        b = biases[b_offset:b_offset + num_b]

        layer.weight.data = torch.from_numpy(w.copy())
        layer.bias.data = torch.from_numpy(b.copy())

        w_offset += num_w
        b_offset += num_b

    print(f"Loaded all layers (w_offset={w_offset}, b_offset={b_offset})")

    # Verify we consumed all weights
    assert w_offset == len(weights), f"Weight mismatch: used {w_offset}, have {len(weights)}"
    assert b_offset == len(biases), f"Bias mismatch: used {b_offset}, have {len(biases)}"

    return model


# =============================================================================
# Export Image for HLS Testbench
# =============================================================================

def export_image_for_hls(img_tensor, output_path):
    """Export image as int8 binary for HLS testbench"""
    img_q = quantize_tensor(img_tensor)
    img_int8 = (img_q * SCALE).numpy().astype(np.int8)
    img_int8.tofile(output_path)
    print(f"  Exported: {output_path} (shape: {img_tensor.shape})")
    return img_q


# =============================================================================
# Test on Full CIFAR-10 Test Set
# =============================================================================

def test_full_cifar10(model, testset):
    """Test on the entire CIFAR-10 test set"""
    model.eval()
    correct = 0
    total = 0

    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)

    with torch.no_grad():
        for images, labels in testloader:
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    return accuracy, correct, total


# =============================================================================
# Test on CIFAR-10
# =============================================================================

def test_on_cifar10():
    transform = transforms.Compose([
        transforms.Resize(224),
        transforms.ToTensor(),
        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])
    ])

    testset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, transform=transform
    )

    model = SqueezeNetHLS(num_classes=10)

    # Find .bin files
    paths = [
        ('checkpoints/hls_weights/weights.bin', 'checkpoints/hls_weights/biases.bin'),
        ('hls_weights/weights.bin', 'hls_weights/biases.bin'),
        ('weights.bin', 'biases.bin'),
    ]

    loaded = False
    for w_path, b_path in paths:
        if os.path.exists(w_path) and os.path.exists(b_path):
            print(f"\nLoading from: {w_path}")
            model = load_weights_from_bin(model, w_path, b_path)
            loaded = True
            break

    if not loaded:
        print("\nERROR: weights.bin and biases.bin not found!")
        print("Please run task2.py first to generate weights.")
        return

    model.eval()

    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

    print("\n" + "="*60)
    print("Testing HLS-Compatible Model on CIFAR-10")
    print("Quantization: Q3.4 (ap_fixed<8,4>)")
    print("="*60)

    # Quick per-class test (10 samples each)
    print("\nPer-class sample results:")
    print("-"*40)

    class_counts = {i: 0 for i in range(10)}
    class_correct = {i: 0 for i in range(10)}

    for idx in range(len(testset)):
        img, label = testset[idx]

        if class_counts[label] >= 10:
            if all(c >= 10 for c in class_counts.values()):
                break
            continue

        class_counts[label] += 1

        with torch.no_grad():
            out = model(img.unsqueeze(0))
            pred = out.argmax(dim=1).item()

        if pred == label:
            class_correct[label] += 1

        if class_counts[label] <= 2:
            status = "✓" if pred == label else "✗"
            print(f"  {status} True: {classes[label]:<12} Pred: {classes[pred]:<12}")

    print("\nPer-class accuracy (10 samples each):")
    print("-"*40)
    for i in range(10):
        acc = 100 * class_correct[i] / 10
        bar = "█" * int(acc/10) + "░" * (10 - int(acc/10))
        print(f"  {classes[i]:<12}: {class_correct[i]:>2}/10  {bar} {acc:>5.1f}%")

    sample_correct = sum(class_correct.values())
    sample_total = sum(class_counts.values())
    print(f"\nSample accuracy: {sample_correct}/{sample_total} = {100*sample_correct/sample_total:.1f}%")

    # Full test set evaluation
    print("\n" + "-"*60)
    print("Running full CIFAR-10 test set evaluation...")
    accuracy, correct, total = test_full_cifar10(model, testset)
    print(f"\n★ Full Test Set Accuracy: {correct}/{total} = {accuracy:.2f}%")
    print("-"*60)

    # Export test images for HLS testbench
    print("\n" + "="*60)
    print("Exporting Test Images for HLS Testbench")
    print("="*60)

    os.makedirs("hls_test_images", exist_ok=True)

    raw_testset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, transform=None
    )

    saved = {i: False for i in range(10)}
    for idx in range(len(raw_testset)):
        raw_img, label = raw_testset[idx]


        if not saved[label]:
            # Save original PNG
            png_path = f"hls_test_images/class_{label}_{classes[label]}.png"
            raw_img.save(png_path)

            # Save preprocessed binary for HLS
            img_tensor, _ = testset[idx]
            bin_path = f"hls_test_images/input_class_{label}.bin"
            export_image_for_hls(img_tensor, bin_path)

            # Also save expected prediction
            with torch.no_grad():
                out = model(img_tensor.unsqueeze(0))
                pred = out.argmax(dim=1).item()
                confidence = F.softmax(out, dim=1)[0, pred].item()

            print(f"  Class {label} ({classes[label]}): Predicted {classes[pred]} ({confidence*100:.1f}%)")

            saved[label] = True

        if all(saved.values()):
            break

    print(f"\nSaved 10 test images to hls_test_images/")
    print("  - PNG files: Original images for reference")
    print("  - BIN files: Preprocessed int8 for HLS testbench")

    print("\n" + "="*60)
    print("✓ Done!")
    print("="*60)


if __name__ == '__main__':
    test_on_cifar10()

